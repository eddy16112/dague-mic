extern "C" %{
/*
 *  Copyright (c) 2010-2012
 *
 *  The University of Tennessee and The University
 *  of Tennessee Research Foundation.  All rights
 *  reserved.
 *
 * @precisions normal z -> s d c
 *
 */
#define PRECISION_z

#include <plasma.h>
#include <core_blas.h>

#include "dague.h"
#include "data_distribution.h"
#include "data_dist/matrix/precision.h"
#include "data_dist/matrix/matrix.h"
#include "dplasma/lib/memory_pool.h"
#include "dplasma/lib/dplasmajdf.h"
#include "data_dist/matrix/two_dim_rectangle_cyclic.h"
#include "data_dist/matrix/sym_two_dim_rectangle_cyclic.h"
#include "scheduling.h"

#include "dplasma.h"

#if defined(HAVE_CUDA)
#include "gpu_data.h"
#include "dplasma/cores/cuda_zgemm.h"
extern int *gpu_counter;
#endif  /* defined(HAVE_CUDA) */

#define RECURSIVE_POTRF
#define RECURSIVE_HERK
#define RECURSIVE_TRSM
//#define RECURSIVE_GEMM

typedef struct cb_data_s {
    dague_execution_unit_t *context;
    dague_execution_context_t *task;
    dague_ddesc_t * A;
    dague_ddesc_t * B;
    dague_ddesc_t * C;
    void (*destruct)( dague_object_t * );
} cb_data_t;

static int complete_recursive_dague_callback(dague_object_t* dague_object, void* cb_data)
{
    int rc = 0;
    cb_data_t* data = (cb_data_t*)cb_data;

    rc = __dague_complete_execution(data->context, data->task);

    if (data->A != NULL) free(data->A);
    if (data->B != NULL) free(data->B);
    if (data->C != NULL) free(data->C);

    data->destruct( dague_object );
    free(data);
    return rc;
}

%}


/* Globals
 */
PRI_CHANGE [type = int hidden = on]
uplo       [type = PLASMA_enum]
descA      [type = "tiled_matrix_desc_t"]
A          [type = "dague_ddesc_t *"]
INFO       [type = "int*"]
smallnb    [type = "int" hidden=on default="(192)" ]

/**************************************************
 *                      POTRF                     *
 **************************************************/
POTRF(k) [high_priority = on]

// Execution space
k = 0..descA.mt-1

// Parallel partitioning
:A(k, k)

// Parameters
RW T <- (k == 0) ? A(k, k) : T HERK(k-1, k)
     -> T TRSM(k+1..descA.mt-1, k)
     -> A(k, k)


; inline_c %{
    if (descA.mb <= smallnb) {
//        printf("small\n");
        return (k >= (descA.mt - PRI_CHANGE)) ? (descA.mt - k) * (descA.mt - k) * (descA.mt - k) : 0x7fffffff-1;
    } else {
        return (k >= (descA.mt - PRI_CHANGE)) ? (descA.mt - k) * (descA.mt - k) * (descA.mt - k) : 1000000000;
    }
%}

BODY
{
    int tempkm = k == descA.mt-1 ? descA.m - k*descA.mb : descA.mb;
    int ldak = BLKLDD( descA, k );
    int iinfo = 0;

#if defined(HAVE_CUDA)
    if (tempkm > smallnb) {
        moesi_master_update( descA.super.moesi_map, GEMM_KEY( &descA, k, k) );
    }
#endif  /* defined(HAVE_CUDA) */

#if defined(RECURSIVE_POTRF)
    if (tempkm > smallnb) {
        two_dim_block_cyclic_t *small_descT;
        dague_object_t *dague_zpotrf;
        cb_data_t      *cbdata_zpotrf;

        small_descT = (two_dim_block_cyclic_t *) malloc(sizeof(two_dim_block_cyclic_t));
        two_dim_block_cyclic_init(small_descT,
                                  matrix_ComplexDouble, matrix_Lapack,
                                  1, 1, 0,
                                  smallnb, smallnb, ldak, tempkm,
                                  0, 0, tempkm, tempkm, 1, 1, 1);
        small_descT->mat = T;

        /* Dague_object */
        dague_zpotrf = dplasma_zpotrf_New(uplo, (tiled_matrix_desc_t *)small_descT, &iinfo );
        //((dague_zpotrf_Lrl_object_t*)dague_zpotrf)->smallnb = smallnb;
        //dague_set_priority( dague_zpotrf, 0x7fffffff-1);

        /* Callback */
        cbdata_zpotrf = (cb_data_t *) malloc(sizeof(cb_data_t));
        cbdata_zpotrf->context = context;
        cbdata_zpotrf->task    = this_task;
        cbdata_zpotrf->A       = (dague_ddesc_t *)small_descT;
        cbdata_zpotrf->B       = NULL;
        cbdata_zpotrf->C       = NULL;
        cbdata_zpotrf->destruct= dplasma_zpotrf_Destruct;
        dague_set_complete_callback(dague_zpotrf,
                                    complete_recursive_dague_callback,
                                    (void *)cbdata_zpotrf);

        dague_enqueue(context->virtual_process->dague_context, dague_zpotrf);
        return -1;

    }
    else
#endif
    {
        DRYRUN(
            CORE_zpotrf(
                uplo, tempkm, T, ldak,
                &iinfo );
            if ( iinfo != 0 && *INFO == 0 )
                *INFO = k*descA.mb+iinfo; /* Should return here */
               );
    }

    printlog(
             "CORE_zpotrf( %d )\n\t( %s, %d, A(%d,%d)[%p], %d)\n",
             k,
             plasma_const(uplo), tempkm, k, k, T, descA.mb );
}
END


/**************************************************
 *                      TRSM                      *
 **************************************************/
TRSM(m, k) [high_priority = on]

// Execution space
m = 1..descA.mt-1
k = 0..m-1

// Parallel partitioning
: A(m, k)

// Parameters
READ  T <- T POTRF(k)
RW    C <- (k == 0) ? A(m, k) : C GEMM(k-1, m, k)
        -> A HERK(k, m)
        -> A GEMM(k, m, k+1..m-1 )
        -> B GEMM(k, m+1..descA.mt-1, m )
        -> A(m, k)


; inline_c %{
    if (descA.mb <= smallnb) {
        return (m >= (descA.mt - PRI_CHANGE)) ? (descA.mt - m) * (descA.mt - m) * (descA.mt - m) + 3 * ((2 * descA.mt) - k - m - 1) * (m - k) : 0x7fffffff-2;
    } else {
        return (m >= (descA.mt - PRI_CHANGE)) ? (descA.mt - m) * (descA.mt - m) * (descA.mt - m) + 3 * ((2 * descA.mt) - k - m - 1) * (m - k) : 1000000000;
    }
%}

BODY
{
    int tempmm = m == descA.mt-1 ? descA.m - m * descA.mb : descA.mb;
    int ldak = BLKLDD( descA, k );
    int ldam = BLKLDD( descA, m );

#if defined(HAVE_CUDA)
    if (tempmm > smallnb || descA.nb > smallnb) {
        moesi_master_update( descA.super.moesi_map, GEMM_KEY( &descA, m, k) );
    }
#endif  /* defined(HAVE_CUDA) */

#if defined(RECURSIVE_TRSM)
    if (tempmm > smallnb || descA.nb > smallnb) {
        two_dim_block_cyclic_t *small_descT, *small_descC;
        dague_object_t* dague_ztrsm;
        cb_data_t  *cbdata_ztrsm;

        small_descT = (two_dim_block_cyclic_t *) malloc(sizeof(two_dim_block_cyclic_t));
        small_descC = (two_dim_block_cyclic_t *) malloc(sizeof(two_dim_block_cyclic_t));

        two_dim_block_cyclic_init(small_descT,
                                  matrix_ComplexDouble, matrix_Lapack,
                                  1, 1, 0,
                                  smallnb, smallnb, ldak, descA.nb,
                                  0, 0, descA.nb, descA.nb, 1, 1, 1);
        small_descT->mat = T;
        two_dim_block_cyclic_init(small_descC,
                                  matrix_ComplexDouble, matrix_Lapack,
                                  1, 1, 0,
                                  smallnb, smallnb, ldam, descA.nb,
                                  0, 0, tempmm, descA.nb, 1, 1, 1);
        small_descC->mat = C;

        dague_ztrsm = dplasma_ztrsm_New(PlasmaRight, PlasmaLower,
                                        PlasmaConjTrans, PlasmaNonUnit,
                                        (dague_complex64_t)1.0,
                                        (tiled_matrix_desc_t *)small_descT,
                                        (tiled_matrix_desc_t *)small_descC );
        //dague_set_priority( dague_ztrsm, 0x7fffffff-2);

        cbdata_ztrsm = (cb_data_t *) malloc(sizeof(cb_data_t));
        cbdata_ztrsm->context = context;
        cbdata_ztrsm->task = this_task;
        cbdata_ztrsm->A = (dague_ddesc_t *) small_descT;
        cbdata_ztrsm->B = (dague_ddesc_t *) small_descC;
        cbdata_ztrsm->C = NULL;
        cbdata_ztrsm->destruct = dplasma_ztrsm_Destruct;
        dague_set_complete_callback(dague_ztrsm,
                                    complete_recursive_dague_callback,
                                    (void *)cbdata_ztrsm);

        dague_enqueue(context->virtual_process->dague_context, dague_ztrsm);
        return -1;
    }
    else
#endif
    {
        DRYRUN(
            CORE_ztrsm(
                PlasmaRight, PlasmaLower, PlasmaConjTrans, PlasmaNonUnit,
                tempmm, descA.nb,
                (dague_complex64_t)1.0, T /*A(k, k)*/, ldak,
                C /*A(m, k)*/, ldam);
               );
    }

    printlog("CORE_ztrsm( %d, %d )\n\t( %s, %s, %s, %s, %d, %d, %f, A(%d,%d)[%p], %d,  A(%d,%d)[%p], %d)\n",
             m, k,
             plasma_const( PlasmaRight ), plasma_const( PlasmaLower ),
             plasma_const( PlasmaConjTrans ), plasma_const( PlasmaNonUnit ),
             tempmm, descA.nb,
             1.0, k, k, T, ldak,
                  m, k, C, ldam);

}
END


/**************************************************
 *                      HERK                      *
 **************************************************/
HERK(k, m) [high_priority = on]

// Execution space
k = 0..descA.mt-2
m = k+1..descA.mt-1

// Parallel partitioning
: A(m, m)

//Parameters
READ  A <- C TRSM(m, k)
RW    T <- (k == 0)   ? A(m, m)    : T HERK(k-1, m)
        -> (m == k+1) ? T POTRF(m) : T HERK(k+1, m)


; inline_c %{
    if (descA.mb <= smallnb) {
        return (m >= (descA.mt - PRI_CHANGE)) ? (descA.mt - m) * (descA.mt - m) * (descA.mt - m) + 3 * (m - k) : 0x7fffffff-2;
    } else {
        return (m >= (descA.mt - PRI_CHANGE)) ? (descA.mt - m) * (descA.mt - m) * (descA.mt - m) + 3 * (m - k) : 1000000000;
    }
%}

BODY
{
    int tempmm = m == descA.mt-1 ? descA.m - m*descA.mb : descA.mb;
    int ldam = BLKLDD( descA, m );

#if defined(HAVE_CUDA)
    if (tempmm > smallnb || descA.mb > smallnb) {
        moesi_master_update( descA.super.moesi_map, GEMM_KEY( &descA, m, m) );
    }
#endif  /* defined(HAVE_CUDA) && */

#if defined(RECURSIVE_HERK)
    if (tempmm > smallnb || descA.mb > smallnb) {
        two_dim_block_cyclic_t *small_descT, *small_descA;
        dague_object_t* dague_zherk;
        cb_data_t  *cbdata_zherk;

        small_descT = (two_dim_block_cyclic_t *) malloc(sizeof(two_dim_block_cyclic_t));
        small_descA = (two_dim_block_cyclic_t *) malloc(sizeof(two_dim_block_cyclic_t));

        two_dim_block_cyclic_init(small_descT,
                                  matrix_ComplexDouble, matrix_Lapack,
                                  1, 1, 0,
                                  smallnb, smallnb, ldam, descA.nb,
                                  0, 0, tempmm, tempmm, 1, 1, 1);
        small_descT->mat = T;
        two_dim_block_cyclic_init(small_descA,
                                  matrix_ComplexDouble, matrix_Lapack,
                                  1, 1, 0,
                                  smallnb, smallnb, ldam, descA.nb,
                                  0, 0, tempmm, descA.nb, 1, 1, 1);
        small_descA->mat = A;

        dague_zherk = dplasma_zherk_New( PlasmaLower, PlasmaNoTrans,
                                         (double)-1.0, (tiled_matrix_desc_t*) small_descA,
                                         (double)1.0,  (tiled_matrix_desc_t*) small_descT);
        //dague_set_priority( dague_zherk, 0x7fffffff-2);

        cbdata_zherk = (cb_data_t *) malloc(sizeof(cb_data_t));
        cbdata_zherk->context = context;
        cbdata_zherk->task = this_task;
        cbdata_zherk->A = (dague_ddesc_t *) small_descA;
        cbdata_zherk->B = (dague_ddesc_t *) small_descT;
        cbdata_zherk->C = NULL;
        cbdata_zherk->destruct = dplasma_zherk_Destruct;
        dague_set_complete_callback(dague_zherk,
                                    complete_recursive_dague_callback,
                                    (void *)cbdata_zherk);

        dague_enqueue(context->virtual_process->dague_context, dague_zherk);
        return -1;
    }
    else
#endif
    {
        DRYRUN(
            CORE_zherk(
                PlasmaLower, PlasmaNoTrans,
                tempmm, descA.mb,
                (double)-1.0, A /*A(m, k)*/, ldam,
                (double) 1.0, T /*A(m, m)*/, ldam);
               );
    }

    printlog(
             "CORE_zherk( %d, %d )\n\t( %s, %s, %d, %d, %f, A(%d,%d)[%p], %d, %f, A(%d,%d)[%p], %d)\n",
             k, m,
             plasma_const( PlasmaLower ), plasma_const( PlasmaNoTrans ),
             tempmm, descA.mb,
             -1.0, m, k, A, ldam,
              1.0, m, m, T, ldam);
}
END

/**************************************************
 *                      GEMM                      *
 **************************************************/
// Name
GEMM(k, m, n)

// Execution space
k = 0   .. descA.mt-3
m = k+2 .. descA.mt-1
n = k+1 .. m-1

// Parallel partitioning
: A(m, n)

// Parameters
READ  A <- C TRSM(m, k)
READ  B <- C TRSM(n, k)
RW    C <- (k == 0)   ? A(m, n)      : C GEMM(k-1, m, n)
        -> (n == k+1) ? C TRSM(m, n) : C GEMM(k+1, m, n)


; inline_c %{
    if (descA.mb <= smallnb) {
        return (m >= (descA.mt - PRI_CHANGE)) ? (descA.mt - m) * (descA.mt - m) * (descA.mt - m) + 3 * ((2 * descA.mt) - m - n - 3) * (m - n) + 6 * (m - k) : 0x7fffffff-3;
    } else {
        return (m >= (descA.mt - PRI_CHANGE)) ? (descA.mt - m) * (descA.mt - m) * (descA.mt - m) + 3 * ((2 * descA.mt) - m - n - 3) * (m - n) + 6 * (m - k) : 0x7fffffff;
    }
%}

BODY
{
    int tempmm = m == descA.mt-1 ? descA.m - m * descA.mb : descA.mb;
    int ldam = BLKLDD( descA, m );
    int ldan = BLKLDD( descA, n );

#if defined(HAVE_CUDA)
    if (tempmm > smallnb || descA.nb > smallnb) {
        if( dague_active_gpu() > 0 ) {
            int rc;

            if( 0 == (rc = gpu_zgemm( context, this_task,
                                      ( n == k+1 ),
                                      PlasmaNoTrans, PlasmaConjTrans,
                                      tempmm, descA.mb, descA.mb,
                                      (dague_complex64_t)-1.0, m, k, &descA, ldam,
                                                               n, k, &descA, ldan,
                                      (dague_complex64_t) 1.0, m, n, &descA, ldam)) )
            	goto FIN;
            if( -1 == rc ) {
            	/* The task is pending in the device, and will be subsequently completed */
            	return -1;
            }
            if( -2 == rc ) {
            	/* The GPU failed to execute this task, but the task was already rescheduled */
                fprintf(stderr, "Unable to disable GPU at runtime. Fatal error.\n");
                exit(2);
            }
    	}
        moesi_master_update( descA.super.moesi_map, GEMM_KEY( &descA, m, n) );
    }
#endif

#if defined(RECURSIVE_GEMM)
    if (tempmm > smallnb || descA.nb > smallnb) {
        two_dim_block_cyclic_t *small_descA;
        two_dim_block_cyclic_t *small_descB;
        two_dim_block_cyclic_t *small_descC;
        dague_object_t *dague_zgemm;
        cb_data_t  *cbdata_zgemm;

        small_descA = (two_dim_block_cyclic_t *) malloc(sizeof(two_dim_block_cyclic_t));
        small_descB = (two_dim_block_cyclic_t *) malloc(sizeof(two_dim_block_cyclic_t));
        small_descC = (two_dim_block_cyclic_t *) malloc(sizeof(two_dim_block_cyclic_t));

        two_dim_block_cyclic_init(small_descA,
                                  matrix_ComplexDouble, matrix_Lapack,
                                  1, 1, 0,
                                  smallnb, smallnb, ldam, descA.nb,
                                  0, 0, tempmm, descA.nb, 1, 1, 1);
        small_descA->mat = A;
        two_dim_block_cyclic_init(small_descB,
                                  matrix_ComplexDouble, matrix_Lapack,
                                  1, 1, 0,
                                  smallnb, smallnb, ldan, descA.nb,
                                  0, 0, descA.mb, descA.nb, 1, 1, 1);
        small_descB->mat = B;
        two_dim_block_cyclic_init(small_descC,
                                  matrix_ComplexDouble, matrix_Lapack,
                                  1, 1, 0, smallnb, smallnb, ldam, descA.nb,
                                  0, 0, tempmm, descA.nb, 1, 1, 1);
        small_descC->mat = C;

        dague_zgemm = dplasma_zgemm_New(PlasmaNoTrans, PlasmaConjTrans,
                                        (dague_complex64_t)-1.0,
                                        (tiled_matrix_desc_t *)small_descA,
                                        (tiled_matrix_desc_t *)small_descB,
                                        (dague_complex64_t) 1.0,
                                        (tiled_matrix_desc_t *)small_descC);
        //dague_set_priority( dague_zgemm, 0x7fffffff-3);

        cbdata_zgemm = (cb_data_t *) malloc(sizeof(cb_data_t));
        cbdata_zgemm->context = context;
        cbdata_zgemm->task = this_task;
        cbdata_zgemm->A = (dague_ddesc_t *) small_descA;
        cbdata_zgemm->B = (dague_ddesc_t *) small_descB;
        cbdata_zgemm->C = (dague_ddesc_t *) small_descC;
        cbdata_zgemm->destruct = dplasma_zgemm_Destruct;
        dague_set_complete_callback(dague_zgemm,
                                    complete_recursive_dague_callback,
                                    (void *)cbdata_zgemm);

        dague_enqueue(context->virtual_process->dague_context, dague_zgemm);
        return -1;

    }
    else
#endif
    {
        DRYRUN(
            CORE_zgemm(
                PlasmaNoTrans, PlasmaConjTrans,
                tempmm, descA.nb, descA.mb,
                (dague_complex64_t)-1.0, A /*A(m, k)*/, ldam,
                                         B /*A(n, k)*/, ldan,
                (dague_complex64_t) 1.0, C /*A(m, n)*/, ldam);
               );
    }

#if defined(HAVE_CUDA)
  FIN:
#endif  /* defined(HAVE_CUDA) */
   printlog("CORE_zgemm( %d, %d, %d )\n\t( %s, %s, %d, %d, %d, %f, A(%d,%d)[%p], %d, A(%d,%d)[%p], %d, %f, A(%d,%d)[%p], %d)\n",
             k, m, n,
             plasma_const( PlasmaNoTrans ),  plasma_const( PlasmaConjTrans ),
             tempmm, descA.mb, descA.mb,
             -1.0, m, k, A, ldam,
                   n, k, B, ldan,
             1.0,  m, n, C, ldam);

}
END
