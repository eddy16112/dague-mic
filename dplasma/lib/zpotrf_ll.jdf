extern "C" %{
/*
 *  Copyright (c) 2010-2012
 *
 *  The University of Tennessee and The University
 *  of Tennessee Research Foundation.  All rights
 *  reserved.
 *
 * @precisions normal z -> s d c
 *
 */
#define PRECISION_z

#include <plasma.h>
#include <core_blas.h>

#include "dague.h"
#include "data_distribution.h"
#include "data_dist/matrix/precision.h"
#include "dplasma/lib/dplasmajdf.h"


#if defined(HAVE_CUDA) && defined(PRECISION_s)
#include "gpu_data.h"
#include "dplasma/cores/cuda_sgemm.h"
extern int *gpu_counter;
extern dague_gpu_data_map_t dague_gpu_map;
#endif  /* defined(HAVE_CUDA) && defined(PRECISION_s) */
%}

/* Globals
 */
NB           [type = int]
SIZE         [type = int]
PRI_CHANGE   [type = int]
uplo         [type = PLASMA_enum]
INFO         [type = "int*"]

/**************************************************
 *                      POTRF                     *
 **************************************************/
POTRF(k) [high_priority = on]

// Execution space
k = 0..SIZE-1

// Parallel partitioning
:A(k, k)

// Parameters
RW T <- (k == 0) ? A(k, k) : T HERK(k, k-1)
     -> T TRSM(k, k+1..SIZE-1)
     -> A(k, k)
WRITE   F -> F GEMM(k, k+1..SIZE-1, 0)

; (k >= (SIZE - PRI_CHANGE)) ? (SIZE - k) * (SIZE - k) * (SIZE - k) : 1000000000

BODY
#if defined(HAVE_CUDA) && defined(PRECISION_s)
    dague_gpu_update_data_version( &dague_gpu_map, GEMM_KEY(k, k) );
#endif  /* defined(HAVE_CUDA) && defined(PRECISION_s) */

    (void) F;
    DRYRUN(
        CORE_zpotrf(
            uplo,
            NB, /*k == A.nt-1 ? A.n-k*A.nb : A.nb,*/
            T /* A(k, k) */, NB, /*A.nb,*/
            INFO )
         );
    printlog(
             "CORE_potrf( %s, %d, A(%d,%d), %d)\n",
             (uplo == PlasmaLower) ? "PlasmaLower" : "PlasmaUpper",
             NB, /*k == A.nt-1 ? A.n-k*A.nb : A.nb,*/
             k, k, NB /*A.nb,*/ );
END


/**************************************************
 *                      TRSM                      *
 **************************************************/
TRSM(k, m) [high_priority = on]

// Execution space
k = 0..SIZE-1
m = k+1..SIZE-1

// Parallel partitioning
: A(m, k)

// Parameters
READ    T <- T POTRF(k)
RW      C <- (k == 0) ? A(m, k) : C GEMM(k, m, k-1)
          -> A HERK(m, k)
          -> A GEMM(m, m+1..SIZE-1, k)
          -> B GEMM(k+1..m-1, m, k)
          -> (m == k+1) ? F HERK(m, 0)
          -> A(m, k)

; (m >= (SIZE - PRI_CHANGE)) ? (SIZE - m) * (SIZE - m) * (SIZE - m) + 3 * (2 * SIZE - k - m - 1) * (m - k) : 1000000000

BODY
#if defined(HAVE_CUDA) && defined(PRECISION_s)
    dague_gpu_update_data_version( &dague_gpu_map, GEMM_KEY(m, k) );
#endif  /* defined(HAVE_CUDA) && defined(PRECISION_s) */

    if( uplo == PlasmaLower ) {
        DRYRUN(
            CORE_ztrsm(
                PlasmaRight, PlasmaLower, PlasmaTrans, PlasmaNonUnit,
                NB, /*m == A.nt-1 ? A.n-m*A.nb : A.nb,*/
                NB, /*A.nb,*/
                (Dague_Complex64_t)1.0, T /*A(k, k)*/, NB, /*A.nb,*/
                                        C /*A(m, k)*/, NB /*A.nb*/ )
            );
        printlog(
                 "CORE_trsm( %s, %s, %s, %s, %d, %d, %f, A(%d,%d), %d, A(%d,%d), %d)\n",
                 "PlasmaRight", "PlasmaLower", "PlasmaTrans", "PlasmaNonUnit",
                 NB, /*m == A.nt-1 ? A.n-m*A.nb : A.nb,*/
                 NB, /*A.nb,*/
                 1.0, k, k, NB, /*A.nb,*/
                 m, k, NB /*A.nb*/ );
    } else {
        DRYRUN(
            CORE_ztrsm(
                PlasmaLeft, PlasmaUpper, PlasmaTrans, PlasmaNonUnit,
                NB, /*m == A.nt-1 ? A.n-m*A.nb : A.nb,*/
                NB, /*A.nb,*/
                (Dague_Complex64_t)1.0, T /*A(k, k)*/, NB, /*A.nb,*/
                                        C /*A(k, m)*/, NB /*A.nb*/ )
            );
        printlog(
                 "CORE_trsm( %s, %s, %s, %s, %d, %d, %f, A(%d,%d), %d, A(%d,%d), %d)\n",
                 "PlasmaLeft", "PlasmaUpper", "PlasmaTrans", "PlasmaNonUnit",
                 NB, /*m == A.nt-1 ? A.n-m*A.nb : A.nb,*/
                 NB, /*A.nb,*/
                 1.0, k, k, NB, /*A.nb,*/
                 k, m, NB /*A.nb*/ );
    }
END


/**************************************************
 *                      HERK                      *
 **************************************************/
HERK_IN_A(k)  [profile = off]
k = 1..SIZE-1

:A(k, k)

READ A <- A(k, k)
       -> T HERK(k, 0..k-1)

BODY
 /* Nothing */
END

HERK_IN_F(k)  [profile = off]
k = 1..SIZE-1

:A(k, k)

READ A <- A(k, k)
       -> F HERK(k, 0..k-1)

BODY
 /* Nothing */
END

HERK(k, n) [high_priority = on]

// Execution space
k = 1..SIZE-1
n = 0..k-1

// Parallel partitioning
: A(n, n)

//Parameters
READ  A <- C TRSM(n, k)
READ  F <- (n == 0) ? C TRSM(k-1, k) : A HERK_IN_F(k)
RW    T <- (n == 0) ? A HERK_IN_A(k) : T HERK(k, n-1)
        -> (n == k-1) ? T POTRF(k) : T HERK(k, n+1)

; (n >= (SIZE - PRI_CHANGE)) ? (SIZE - n) * (SIZE - n) * (SIZE - n) + 3 * (n - k) : 1000000000

BODY
#if defined(HAVE_CUDA) && defined(PRECISION_s)
    dague_gpu_update_data_version( &dague_gpu_map, GEMM_KEY(k, k) );
#endif  /* defined(HAVE_CUDA) && defined(PRECISION_s) */
    (void) F;
    if( uplo == PlasmaLower ) {
        DRYRUN(
            CORE_zherk(
                PlasmaLower, PlasmaNoTrans,
                NB, /*k == A.nt-1 ? A.n-k*A.nb : A.nb,*/
                NB, /*A.nb,*/
                (double)-1.0, A /*A(k, n)*/, NB, /*A.nb,*/
                (double) 1.0, T /*A(k, k)*/, NB /*A.nb*/ )
            );
        printlog(
                 "CORE_herk( %s, %s, %d, %d, %f, A(%d,%d), %d, %f, A(%d,%d), %d)\n",
                 "PlasmaLower", "PlasmaNoTrans",
                 NB, /*k == A.nt-1 ? A.n-k*A.nb : A.nb,*/
                 NB, /*A.nb,*/
                 (double)-1.0, k, n, NB, /*A.nb,*/
                 (double)1.0, k, k, NB /*A.nb*/ );

    } else {
        DRYRUN(
            CORE_zherk(
                PlasmaUpper, PlasmaTrans,
                NB, /*k == A.nt-1 ? A.n-k*A.nb : A.nb,*/
                NB, /*A.nb,*/
                (double)-1.0, A /*A(n, k)*/, NB, /*A.nb,*/
                (double) 1.0, T /*A(k, k)*/, NB /*A.nb*/ )
            );
        printlog(
                 "CORE_herk( %s, %s, %d, %d, %f, A(%d,%d), %d, %f, A(%d,%d), %d)\n",
                 "PlasmaUpper", "PlasmaTrans",
                 NB, /*k == A.nt-1 ? A.n-k*A.nb : A.nb,*/
                 NB, /*A.nb,*/
                 (double)-1.0, n, k, NB, /*A.nb,*/
                 (double)1.0, k, k, NB /*A.nb*/ );
    }
END


/**************************************************
 *                      GEMM                      *
 **************************************************/
GEMM_IN_A(k, m)  [profile = off]
k = 0..SIZE-1
m = k+1..SIZE-1

:A(m, k)

READ A <- A(m, k)
       -> C GEMM(k, m, 0..k-1)

BODY
  /* Nothing */
END

GEMM_IN_F(k, m)  [profile = off]
k = 0..SIZE-1
m = k+1..SIZE-1

:A(m, k)

READ A <- A(m, k)
       -> F GEMM(k, m, 0..k-1)

BODY
  /* Nothing */
END

GEMM(k, m, n)

// Execution space
k = 0..SIZE-1
m = k+1..SIZE-1
n = 0..k-1

// Parallel partitioning
: A(m, n)

// Parameters
READ  A <- C TRSM(n, k)
READ  B <- C TRSM(n, m)
READ  F <- (n == 0) ? F POTRF(k) : A GEMM_IN_F(k, m)   /* It's A(n,k) but we need to swap parameter for the parser */
RW    C <- (n == 0) ? A GEMM_IN_A(k, m) : C GEMM(k, m, n-1)
        -> (n == k-1) ? C TRSM(k, m) : C GEMM(k, m, n+1)

; (m >= (SIZE - PRI_CHANGE)) ? (SIZE - m) * (SIZE - m) * (SIZE - m) + 3 * (2 * SIZE - m - n - 3) * (m - n) + 6 * (m - k) : 1000000000

BODY
#if defined(HAVE_CUDA) && defined(PRECISION_s)
    if( dague_active_gpu() == 1 ) {
        int rc;

        if( 0 == (rc = gpu_sgemm( context, this_task, uplo )) )
            goto FIN;
        if( -1 == rc ) {
            /* We're done, but the task has been already destroyed */
            return -1;
        }
        if( -2 == rc ) {
            /* The GPU failed to execute this task, but the task was already rescheduled */
            fprintf(stderr, "Unable to disable GPU at runtime. Fatal error.\n");
            exit(2);
        }
        /* Continue with the task on the cores */
    }
    dague_gpu_update_data_version( &dague_gpu_map, GEMM_KEY(m, k) );
#endif  /* defined(HAVE_CUDA) && defined(PRECISION_s) */

    (void) F;
    if( uplo == PlasmaLower ) {
        DRYRUN(
            CORE_zgemm(
                PlasmaNoTrans, PlasmaTrans,
                NB, /*m == A.nt-1 ? A.n-m*A.nb : A.nb,*/
                NB, /*A.nb,*/
                NB, /*A.nb,*/
                (Dague_Complex64_t)-1.0, B /*A(m, n)*/, NB, /*A.nb,*/
                                         A /*A(k, n)*/, NB, /*A.nb,*/
                (Dague_Complex64_t) 1.0, C /*A(m, k)*/, NB /*A.nb*/ )
            );
        printlog(
                 "CORE_gemm( %s, %s, %d, %d, %d, %f, A(%d,%d), %d, A(%d,%d), %d, %f, A(%d,%d), %d)\n",
                 "PlasmaNoTrans", "PlasmaTrans",
                 NB, /*m == A.nt-1 ? A.n-m*A.nb : A.nb,*/
                 NB, /*A.nb,*/
                 NB, /*A.nb,*/
                 -1.0, m, n, NB, /*A.nb,*/
                 k, n, NB, /*A.nb,*/
                 1.0, m, k, NB /*A.nb*/ );
    } else {
        DRYRUN(
            CORE_zgemm(
                PlasmaTrans, PlasmaNoTrans,
                NB, /*m == A.nt-1 ? A.n-m*A.nb : A.nb,*/
                NB, /*A.nb,*/
                NB, /*A.nb,*/
                (Dague_Complex64_t)-1.0, A /*A(n, k)*/, NB, /*A.nb,*/
                                         B /*A(n, m)*/, NB, /*A.nb,*/
                (Dague_Complex64_t)1.0,  C /*A(k, m)*/, NB /*A.nb*/ )
            );
        printlog(
                 "CORE_gemm( %s, %s, %d, %d, %d, %f, A(%d,%d), %d, A(%d,%d), %d, %f, A(%d,%d), %d)\n",
                 "PlasmaTrans", "PlasmaNoTrans",
                 NB, /*m == A.nt-1 ? A.n-m*A.nb : A.nb,*/
                 NB, /*A.nb,*/
                 NB, /*A.nb,*/
                 -1.0, n, k, NB, /*A.nb,*/
                 n, m, NB, /*A.nb,*/
                 1.0, k, m, NB /*A.nb*/ );
    }
#if defined(HAVE_CUDA) && defined(PRECISION_s)
FIN:
#endif
END
