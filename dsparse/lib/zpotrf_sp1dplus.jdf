extern "C" %{
  /**
   * PLASMA include for defined and constants.
   *
   * @precisions normal z -> s d c
   *
   */
#include <plasma.h>
#include <core_blas.h>

#include "dague.h"
#include "data_distribution.h"
#include "memory_pool.h"
#include "dplasma/lib/dplasmajdf.h"

#include "data_dist/sparse-matrix/pastix_internal/pastix_internal.h"
#include "data_dist/sparse-matrix/sparse-matrix.h"
#include "dsparse/cores/dsparse_zcores.h"

#define PRECISION_z

#if defined(HAVE_CUDA)
#include "gpu_data.h"
#include "dsparse/cores/cuda_zpotrfsp_gemm.h"
extern int *gpu_counter;
#endif  /* defined(HAVE_CUDA) */
%}

/* Globals
 */
descA    [type = "sparse_matrix_desc_t *"]
A        [type = "dague_ddesc_t *"]
datacode [type = "SolverMatrix*" default="&(descA->pastix_data->solvmatr)" hidden=on]
cblknbr  [type = "dague_int_t"   default="descA->pastix_data->solvmatr.cblknbr - 1" hidden=on]
bloknbr  [type = "dague_int_t"   default="descA->pastix_data->solvmatr.bloknbr - 2" hidden=on] /* -2 to avoid last diagonal block */
p_work   [type = "dague_memory_pool_t *" size = "datacode->coefmax * sizeof(dague_complex64_t)"]

/**************************************************
 *                POTRF_TRSM                      *
 * panel factorization: do trf of diagonal and    *
 *                    : trsm on off-diagonal      *
 **************************************************/
POTRF_TRSM(k) [high_priority = on]

// Execution space
k = 0..cblknbr
gcblk2list= inline_c %{ return UPDOWN_GCBLK2LIST(UPDOWN_LOC2GLOB( k )); %}
browk     = inline_c %{ if ( gcblk2list != -1 ) return UPDOWN_LISTPTR( gcblk2list   ); else return -1; %}
browk1    = inline_c %{ if ( gcblk2list != -1 ) return UPDOWN_LISTPTR( gcblk2list+1 ); else return -1; %}
lastbrow  = inline_c %{ if (browk1 > 0) return UPDOWN_LISTBLOK(browk1-1); else return 0; %}
firstblok = inline_c %{ return SYMB_BLOKNUM(k); %}
lastblok  = inline_c %{ return SYMB_BLOKNUM(k+1); %}

// Parallel partitioning
:A(0, k) // Should match SOLV_COEFTAB(k)

// Parameters
/* C is A(k) if it's a leaf or get the cblk from the last update */
RW A <- ( browk == browk1 ) ? A(0, k) : C GEMM( lastbrow )
     -> A GEMM(firstblok+1..lastblok-1)
     -> A(0, k)

; inline_c %{ return - TASK_PRIONUM(k); %}

BODY
{
#if defined(HAVE_CUDA)
    moesi_master_update( descA->super.moesi_map, KERNEL_KEY( descA, k ) );
#endif  /* defined(HAVE_CUDA) && defined(PRECISION_s) */

#if defined(ACCESS_STATISTICS)
    if ( browk == browk1 ) {
        fprintf(stderr, "Access %lu %lu\n", descA->cblksize[k], descA->cblksize[k+1]-descA->cblksize[k] );
    }
#endif

    DRYRUN(
           core_zpotrfsp1d(A, datacode, k, descA->pastix_data->sopar.espilondiag );
           );
    printlog(
             "thread %d compute_1dplus( cblknum=%d, browk=%d, browk1=%d, lastbrow=%d, firstblok=%d, lastblok=%d )\n",
             context->eu_id, k, browk, browk1, lastbrow, firstblok, lastblok);
}
END

/**************************************************
 *                      GEMM                      *
 * update the trailing matrix with the panel      *
 * k-th block updating corresponding.
 **************************************************/

GEMM(k)

// Execution space
k = 0..bloknbr
fcblk  = inline_c %{ return SYMB_CBLKNUM(k); %}                                    // index of the diagonal block in the row that k-th block belongs to
cblk   = inline_c %{ return sparse_matrix_get_lcblknum( descA, (dague_int_t)k ); %}// diagonal block in the column that k-th block belongs to, TODO: store cblknum in symbblok
phony  = inline_c %{ return k == SYMB_BLOKNUM( cblk ); %}                          // diagonal block?
prev   = inline_c %{ if (phony) return 0; else return sparse_matrix_get_listptr_prev( descA, (dague_int_t)k, (dague_int_t)fcblk ); %} // previous column updating fcblk-th column
next   = inline_c %{ if (phony) return 0; else return sparse_matrix_get_listptr_next( descA, (dague_int_t)k, (dague_int_t)fcblk ); %} // next column updating fcblk-th column

// Parallel partitioning
:A(0, fcblk)

// Parameters
READ  A <- phony ? A(0, fcblk) : A POTRF_TRSM(cblk)       // if off-diagonal, then take output from trsm
RW    C <- ( prev == 0 ) ? A(0, fcblk) : C GEMM( prev )   // if off-diagonal, then take output from gemm by the previous column
        -> phony ? A(0, fcblk)
        -> ((!phony) && (next == 0)) ? A POTRF_TRSM( fcblk ) // if diagonal in the next column, then do trsm
        -> ((!phony) && (next != 0)) ? C GEMM( next )        // if off-diagonal in the next column, then do gemm

; inline_c %{ return - TASK_PRIONUM(fcblk); %}

BODY
    if (!phony) {

#if defined(ACCESS_STATISTICS)
        if ( prev == 0 ) {
            fprintf(stderr, "Access %lu %lu\n", descA->cblksize[fcblk], descA->cblksize[fcblk+1]-descA->cblksize[fcblk] );
        }
#endif

#if defined(HAVE_CUDA)
        printlog(
                 "thread %d compute_1dgemm START ( k=%d, fcblk=%d, cblk=%d, prev=%d, next=%d )\n",
                 context->eu_id, k, fcblk, cblk, prev, next);

        if( dague_active_gpu() > 0 ) {
            int rc;

            if( 0 == (rc = gpu_zpotrfsp_gemm( context, this_task,
                                              (next == 0),
                                              cblk, k, fcblk,
                                              descA)) ) {
                printlog(
                         "thread %d compute_1dgemm( k=%d, fcblk=%d, cblk=%d, prev=%d, next=%d ) - GPU(0)\n",
                         context->eu_id, k, fcblk, cblk, prev, next);
                goto FIN;
            }
            if( -1 == rc ) {
                printlog(
                         "thread %d compute_1dgemm( k=%d, fcblk=%d, cblk=%d, prev=%d, next=%d ) - GPU(-1)\n",
                         context->eu_id, k, fcblk, cblk, prev, next);
                /* We're done, but the task has been already destroyed */
                return -1;
            }
            if( -2 == rc ) {
                /* The GPU failed to execute this task, but the task was already rescheduled */
                fprintf(stderr, "Unable to disable GPU at runtime. Fatal error.\n");
                exit(2);
            }
            /* Continue with the task on the cores */
        }
        moesi_master_update( descA->super.moesi_map, KERNEL_KEY( descA, fcblk ) );
#endif  /* defined(HAVE_CUDA) && defined(PRECISION_s) */

        dague_complex64_t *work = (dague_complex64_t *)dague_private_memory_pop( p_work );

        DRYRUN(
               core_zpotrfsp1d_gemm(cblk, k, fcblk, A, C, work, datacode);
               );
        printlog(
                 "thread %d compute_1dgemm( k=%d, fcblk=%d, cblk=%d, prev=%d, next=%d )\n",
                 context->eu_id, k, fcblk, cblk, prev, next);

        dague_private_memory_push( p_work, (void *)work );
    } else {
        printlog(
                 "thread %d phony_gemm( k=%d, fcblk=%d, cblk=%d, prev=%d, next=%d )\n",
                 context->eu_id, k, fcblk, cblk, prev, next);
    }

#if defined(HAVE_CUDA)
 FIN:
#endif
END
